{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCfB3P9qhzoN",
        "outputId": "26951fe8-14cc-4b0a-add3-6d7781459576"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 11 18:09:46 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N4khlOOhHX5",
        "outputId": "a2ddc06b-a35d-4c02-ea0c-e3f5458b622d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul_naive.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#define N 1024\n",
        "\n",
        "\n",
        "__global__ void matrixMulNaive(const float* A, const float* B, float* C, int n) {\n",
        "    int row=blockIdx.y*blockDim.y +threadIdx.y;\n",
        "    int col=blockIdx.x*blockDim.x +threadIdx.x;\n",
        "    if (row <n && col<n) {\n",
        "        float val=0.0f;\n",
        "        for (int k=0; k< n; ++k)\n",
        "            val += A[row*n + k]*B[k * n + col];\n",
        "        C[row*n + col] = val;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main() {\n",
        "    int size = N * N * sizeof(float);\n",
        "    float *h_A = (float*)malloc(size);\n",
        "    float *h_B = (float*)malloc(size);\n",
        "    float *h_C = (float*)malloc(size);\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "        h_B[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, size);\n",
        "    cudaMalloc(&d_B, size);\n",
        "    cudaMalloc(&d_C, size);\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "    dim3 threads(16, 16);\n",
        "    dim3 blocks((N + threads.x - 1) / threads.x, (N + threads.y - 1) / threads.y);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // run kernel\n",
        "    cudaEventRecord(start);\n",
        "    matrixMulNaive<<<blocks, threads>>>(d_A, d_B, d_C, N);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float ms = 0.0f;\n",
        "    cudaEventElapsedTime(&ms, start, stop);\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "    double flops = 2.0 * N * N * N;\n",
        "    double gflops = flops / (ms * 1e6);\n",
        "    std::cout << \"Native CUDA Matrix Multiplication:\\n\";\n",
        "    std::cout << ms << \" ms,  Performance: \" << gflops << \" GFLOPS\\n\";\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "// ###### COMPILE ###########\n",
        "//!nvcc -O3 -arch=sm_75 matrix_mul_naive.cu -o matrix_mul_naive\n",
        "//!./matrix_mul_naive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD9TkqHbh8o-",
        "outputId": "19b827ab-e6d2-4092-e649-2b113cb12726"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_mul_naive.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -arch=sm_75 matrix_mul_naive.cu -o matrix_mul_naive\n",
        "!./matrix_mul_naive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyXok6RX99I9",
        "outputId": "ad335e5e-892a-4bf8-b777-efdd929249d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Native CUDA Matrix Multiplication:\n",
            "9.23757 ms,  Performance: 232.473 GFLOPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul_tiled_prof.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define TILE 16\n",
        "\n",
        "__global__ void matmul_naive(const float *A,const float *B,float *C,int M,int N,int K){\n",
        " int row=blockIdx.y*blockDim.y+threadIdx.y;\n",
        " int col=blockIdx.x*blockDim.x+threadIdx.x;\n",
        " if(row<M && col<K){\n",
        "   float val=0;\n",
        "   for(int i=0;i<N;i++)\n",
        "     val+=A[row*N+i]*B[i*K+col];\n",
        "   C[row*K+col]=val;\n",
        " }\n",
        "}\n",
        "\n",
        "__global__ void matmul_tiled(const float *A,const float *B,float *C,int M,int N,int K){\n",
        " __shared__ float As[TILE][TILE];\n",
        " __shared__ float Bs[TILE][TILE];\n",
        " int row=blockIdx.y*TILE+threadIdx.y;\n",
        " int col=blockIdx.x*TILE+threadIdx.x;\n",
        " float val=0.0f;\n",
        " for(int t=0;t<(N+TILE-1)/TILE;t++){\n",
        "   if(row<M && t*TILE+threadIdx.x<N)\n",
        "     As[threadIdx.y][threadIdx.x]=A[row*N+t*TILE+threadIdx.x];\n",
        "   else As[threadIdx.y][threadIdx.x]=0.0f;\n",
        "\n",
        "   if(col<K && t*TILE+threadIdx.y<N)\n",
        "     Bs[threadIdx.y][threadIdx.x]=B[(t*TILE+threadIdx.y)*K+col];\n",
        "   else Bs[threadIdx.y][threadIdx.x]=0.0f;\n",
        "   __syncthreads();\n",
        "\n",
        "   for(int i=0;i<TILE;i++)\n",
        "     val+=As[threadIdx.y][i]*Bs[i][threadIdx.x];\n",
        "   __syncthreads();\n",
        " }\n",
        " if(row<M && col<K) C[row*K+col]=val;\n",
        "}\n",
        "\n",
        "void fill(float *a,int m,int n){\n",
        "  for(int i=0;i<m*n;i++) a[i]=(float)(rand()%10);\n",
        "}\n",
        "\n",
        "int main(){\n",
        " int M=1024,N=1024,K=1024;\n",
        " size_t sA=M*N*sizeof(float), sB=N*K*sizeof(float), sC=M*K*sizeof(float);\n",
        " float *hA=(float*)malloc(sA);\n",
        " float *hB=(float*)malloc(sB);\n",
        " float *hC=(float*)malloc(sC);\n",
        " fill(hA,M,N); fill(hB,N,K);\n",
        " float *dA,*dB,*dC;\n",
        " cudaMalloc(&dA,sA); cudaMalloc(&dB,sB); cudaMalloc(&dC,sC);\n",
        " cudaMemcpy(dA,hA,sA,cudaMemcpyHostToDevice);\n",
        " cudaMemcpy(dB,hB,sB,cudaMemcpyHostToDevice);\n",
        " dim3 block(TILE,TILE);\n",
        " dim3 grid((K+TILE-1)/TILE,(M+TILE-1)/TILE);\n",
        "\n",
        " cudaEvent_t start,stop;\n",
        " cudaEventCreate(&start); cudaEventCreate(&stop);\n",
        "\n",
        " cudaEventRecord(start);\n",
        " matmul_naive<<<grid,block>>>(dA,dB,dC,M,N,K);\n",
        " cudaEventRecord(stop);\n",
        " cudaEventSynchronize(stop);\n",
        " float ms1;\n",
        " cudaEventElapsedTime(&ms1,start,stop);\n",
        " double gflops1=2.0*M*N*K/(ms1/1000.0)/1e9;\n",
        " printf(\"Naive: %.4f ms  %.2f GFLOPS\\n\",ms1,gflops1);\n",
        "\n",
        " cudaMemset(dC,0,sC);\n",
        " cudaEventRecord(start);\n",
        " matmul_tiled<<<grid,block>>>(dA,dB,dC,M,N,K);\n",
        " cudaEventRecord(stop);\n",
        " cudaEventSynchronize(stop);\n",
        " float ms2;\n",
        " cudaEventElapsedTime(&ms2,start,stop);\n",
        " double gflops2=2.0*M*N*K/(ms2/1000.0)/1e9;\n",
        " printf(\"Tiled: %.4f ms  %.2f GFLOPS\\n\",ms2,gflops2);\n",
        "\n",
        " cudaFree(dA); cudaFree(dB); cudaFree(dC);\n",
        " free(hA); free(hB); free(hC);\n",
        " return 0;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "//!nvcc -O3 -arch=sm_75 matrix_mul_tiled_prof.cu -o matrix_mul_tiled_prof\n",
        "//!nvprof ./matrix_mul_tiled_prof"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN2rJ3Z9GWio",
        "outputId": "37e09d2f-9a93-4a5c-ee2f-e76812f23a40"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_mul_tiled_prof.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -arch=sm_75 matrix_mul_tiled_prof.cu -o matrix_mul_tiled_prof\n",
        "!nvprof ./matrix_mul_tiled_prof"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2J-ZRxqGjof",
        "outputId": "b6b1f714-c2a3-4c60-97fe-7cb2c6980110"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1172== NVPROF is profiling process 1172, command: ./matrix_mul_tiled_prof\n",
            "Naive: 9.2792 ms  231.43 GFLOPS\n",
            "Tiled: 5.7994 ms  370.30 GFLOPS\n",
            "==1172== Profiling application: ./matrix_mul_tiled_prof\n",
            "==1172== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   55.65%  9.1904ms         1  9.1904ms  9.1904ms  9.1904ms  matmul_naive(float const *, float const *, float*, int, int, int)\n",
            "                   35.10%  5.7954ms         1  5.7954ms  5.7954ms  5.7954ms  matmul_tiled(float const *, float const *, float*, int, int, int)\n",
            "                    9.16%  1.5131ms         2  756.53us  755.79us  757.26us  [CUDA memcpy HtoD]\n",
            "                    0.09%  14.368us         1  14.368us  14.368us  14.368us  [CUDA memset]\n",
            "      API calls:   82.31%  83.237ms         3  27.746ms  62.278us  83.091ms  cudaMalloc\n",
            "                   14.82%  14.988ms         2  7.4942ms  5.7961ms  9.1923ms  cudaEventSynchronize\n",
            "                    1.89%  1.9122ms         2  956.11us  924.96us  987.26us  cudaMemcpy\n",
            "                    0.58%  585.42us         3  195.14us  134.94us  235.22us  cudaFree\n",
            "                    0.16%  164.44us         2  82.221us  12.386us  152.06us  cudaLaunchKernel\n",
            "                    0.16%  163.31us       114  1.4320us     103ns  80.129us  cuDeviceGetAttribute\n",
            "                    0.02%  18.136us         4  4.5340us  3.4090us  5.7830us  cudaEventRecord\n",
            "                    0.02%  18.030us         1  18.030us  18.030us  18.030us  cudaMemset\n",
            "                    0.01%  13.339us         1  13.339us  13.339us  13.339us  cuDeviceGetName\n",
            "                    0.01%  11.506us         2  5.7530us     648ns  10.858us  cudaEventCreate\n",
            "                    0.01%  5.2020us         1  5.2020us  5.2020us  5.2020us  cuDeviceGetPCIBusId\n",
            "                    0.00%  3.3880us         2  1.6940us  1.4280us  1.9600us  cudaEventElapsedTime\n",
            "                    0.00%  2.5170us         2  1.2580us     194ns  2.3230us  cuDeviceGet\n",
            "                    0.00%  1.6240us         3     541ns     109ns  1.1480us  cuDeviceGetCount\n",
            "                    0.00%  1.1980us         1  1.1980us  1.1980us  1.1980us  cuDeviceTotalMem\n",
            "                    0.00%     362ns         1     362ns     362ns     362ns  cuModuleGetLoadingMode\n",
            "                    0.00%     305ns         1     305ns     305ns     305ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    }
  ]
}